# Contents: Multi-Armed Bandits (MAB)
This will focus on Multi Armed Bandit Problems.

- [Topics in Sutton and Barto Book](https://github.com/kkm24132/ReinforcementLearning/blob/main/02_MAB/ReadMe.md#topics-in-sutton-and-barto-book)
- [Understanding Points](https://github.com/kkm24132/ReinforcementLearning/blob/main/02_MAB/ReadMe.md#understanding-points)
- [Exercises and Problem Solving](https://github.com/kkm24132/ReinforcementLearning/blob/main/02_MAB/ReadMe.md#exercises-and-problem-solving)


## Topics in Sutton and Barto Book
- A k-armed Bandit Problem
- Action-Value Methods
- The 10-armed TestBed
- Incremental Implementation
- Tracking a NonStationary Problem
- Optimistic Initial Values
- UCB Action Selection
- Gradient Bandit Algorithms
- Associative Search (Contextual Bandits)

[Back to Top](https://github.com/kkm24132/ReinforcementLearning/blob/main/02_MAB/ReadMe.md#contents-multi-armed-bandits-mab)

## Understanding Points
- Multi-armed Bandits is a basic RL setting onvolving one state but multiple actions
- Action-Value Methods
  - Estimate the values of actions
  - Use the estimates obtained for action selection decisions

[Back to Top](https://github.com/kkm24132/ReinforcementLearning/blob/main/02_MAB/ReadMe.md#contents-multi-armed-bandits-mab)

## Exercises and Problem Solving


[Back to Top](https://github.com/kkm24132/ReinforcementLearning/blob/main/02_MAB/ReadMe.md#contents-multi-armed-bandits-mab)
